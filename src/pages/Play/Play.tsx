"use client";

import { useState, useRef, useEffect } from "react";
import { Mic, MicOff, Volume2 } from "lucide-react";
import characterImage from "../../assets/character.png";
import backgroundImage from "../../assets/EpisodeBack.png";
import { useLocation } from "react-router";

// SpeechRecognition íƒ€ì… ì„ ì–¸ (ê¸°ì¡´ê³¼ ë™ì¼)
interface SpeechRecognitionEvent extends Event {
  results: SpeechRecognitionResultList;
  resultIndex: number;
}

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  start(): void;
  stop(): void;
  onstart: ((this: SpeechRecognition, ev: Event) => any) | null;
  onresult:
    | ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => any)
    | null;
  onend: ((this: SpeechRecognition, ev: Event) => any) | null;
  onerror:
    | ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => any)
    | null;
}

declare global {
  interface Window {
    SpeechRecognition?: new () => SpeechRecognition;
    webkitSpeechRecognition?: new () => SpeechRecognition;
  }
}

export default function Play() {
  const [messages, setMessages] = useState<{ speaker: string; text: string }[]>(
    [{ speaker: "", text: "ì•ˆë…•~ ë§Œë‚˜ì„œ ë°˜ê°€ì›Œ!" }]
  );
  const [isLoading, setIsLoading] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState("");

  // ë””ë²„ê¹…ì„ ìœ„í•œ ìƒˆë¡œìš´ ìƒíƒœë“¤
  const [audioLevel, setAudioLevel] = useState(0);
  const [recordingDuration, setRecordingDuration] = useState(0);
  const [debugLogs, setDebugLogs] = useState<string[]>([]);
  const [showDebugPanel, setShowDebugPanel] = useState(false);
  const [recognitionState, setRecognitionState] = useState<
    "idle" | "starting" | "running" | "stopping"
  >("idle");

  const recognitionRef = useRef<SpeechRecognition | null>(null);
  const audioContextRef = useRef<AudioContext | null>(null);
  const analyserRef = useRef<AnalyserNode | null>(null);
  const microphoneRef = useRef<MediaStreamAudioSourceNode | null>(null);
  const streamRef = useRef<MediaStream | null>(null);
  const recordingStartTime = useRef<number | null>(null);
  const animationRef = useRef<number | null>(null);

  const location = useLocation();
  // selectedEpisode ë³€ìˆ˜ ì œê±°í•˜ê³  í•„ìš”ì‹œ ì§ì ‘ location.state ì‚¬ìš©

  const [myName, characterName, characterId] = [
    "ê¹€ìœ¤ë°°",
    "ìºë¦­í„° ì´ë¦„ ë„£ì–´",
    "ìºë¦­í„° ì•„ì´ë””ë„£ì–´",
  ];

  // ë””ë²„ê·¸ ë¡œê·¸ ì¶”ê°€ í•¨ìˆ˜
  const addDebugLog = (message: string) => {
    const timestamp = new Date().toLocaleTimeString();
    setDebugLogs((prev) => [...prev.slice(-9), `[${timestamp}] ${message}`]);
    console.log(`[Voice Debug] ${message}`);
  };

  // ì˜¤ë””ì˜¤ ë ˆë²¨ ì¸¡ì • í•¨ìˆ˜
  const measureAudioLevel = () => {
    if (!analyserRef.current) return;

    const dataArray = new Uint8Array(analyserRef.current.frequencyBinCount);
    analyserRef.current.getByteFrequencyData(dataArray);

    // í‰ê·  ì˜¤ë””ì˜¤ ë ˆë²¨ ê³„ì‚°
    const average =
      dataArray.reduce((acc, value) => acc + value, 0) / dataArray.length;
    setAudioLevel(Math.round(average));

    // ë…¹ìŒ ì‹œê°„ ì—…ë°ì´íŠ¸
    if (recordingStartTime.current) {
      const duration = Math.floor(
        (Date.now() - recordingStartTime.current) / 1000
      );
      setRecordingDuration(duration);
    }

    if (isRecording) {
      animationRef.current = requestAnimationFrame(measureAudioLevel);
    }
  };

  // ë§ˆì´í¬ ê¶Œí•œ ë° ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ì„¤ì •
  const setupAudioMonitoring = async () => {
    try {
      addDebugLog("ë§ˆì´í¬ ê¶Œí•œ ìš”ì²­ ì¤‘...");
      const stream = await navigator.mediaDevices.getUserMedia({
        audio: {
          echoCancellation: true,
          noiseSuppression: true,
          sampleRate: 44100,
        },
      });

      streamRef.current = stream;
      addDebugLog("ë§ˆì´í¬ ê¶Œí•œ ìŠ¹ì¸ë¨");

      // AudioContext ìƒì„±
      audioContextRef.current = new (window.AudioContext ||
        (window as any).webkitAudioContext)();
      const audioContext = audioContextRef.current;

      // ë§ˆì´í¬ ì…ë ¥ì„ AudioContextì— ì—°ê²°
      microphoneRef.current = audioContext.createMediaStreamSource(stream);

      // ë¶„ì„ê¸° ë…¸ë“œ ìƒì„±
      analyserRef.current = audioContext.createAnalyser();
      analyserRef.current.fftSize = 256;

      // ë§ˆì´í¬ë¥¼ ë¶„ì„ê¸°ì— ì—°ê²°
      microphoneRef.current.connect(analyserRef.current);

      addDebugLog("ì˜¤ë””ì˜¤ ëª¨ë‹ˆí„°ë§ ì„¤ì • ì™„ë£Œ");
    } catch (error) {
      addDebugLog(`ë§ˆì´í¬ ì„¤ì • ì‹¤íŒ¨: ${error}`);
      console.error("ë§ˆì´í¬ ì„¤ì • ì˜¤ë¥˜:", error);
    }
  };

  // ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
  useEffect(() => {
    setupAudioMonitoring();

    if ("webkitSpeechRecognition" in window || "SpeechRecognition" in window) {
      const SpeechRecognition =
        window.SpeechRecognition || window.webkitSpeechRecognition;
      if (SpeechRecognition) {
        recognitionRef.current = new SpeechRecognition();

        const recognition = recognitionRef.current;
        recognition.continuous = true;
        recognition.interimResults = true;
        recognition.lang = "ko-KR";

        recognition.onstart = () => {
          addDebugLog("ìŒì„± ì¸ì‹ ì‹œì‘ë¨");
          setIsRecording(true);
          setRecognitionState("running");
          recordingStartTime.current = Date.now();
          setRecordingDuration(0);
          measureAudioLevel();
        };

        recognition.onresult = (event: SpeechRecognitionEvent) => {
          let finalTranscript = "";
          let interimTranscript = "";

          for (let i = event.resultIndex; i < event.results.length; i++) {
            const transcript = event.results[i][0].transcript;
            const confidence = event.results[i][0].confidence;

            if (event.results[i].isFinal) {
              finalTranscript += transcript;
              addDebugLog(
                `ìµœì¢… í…ìŠ¤íŠ¸ ì¸ì‹: "${transcript}" (ì‹ ë¢°ë„: ${
                  confidence?.toFixed(2) || "N/A"
                })`
              );
            } else {
              interimTranscript += transcript;
            }
          }

          setTranscript(finalTranscript + interimTranscript);

          if (interimTranscript) {
            addDebugLog(`ì„ì‹œ í…ìŠ¤íŠ¸: "${interimTranscript}"`);
          }
        };

        recognition.onend = () => {
          addDebugLog("ìŒì„± ì¸ì‹ ì¢…ë£Œë¨");
          setRecognitionState("idle");

          // onendì—ì„œ ìƒíƒœ ì´ˆê¸°í™”í•˜ì§€ ë§ê³ , ì´ë¯¸ ì´ˆê¸°í™”ëœ ìƒíƒœë¼ë©´ ìŠ¤í‚µ
          if (!isRecording) {
            addDebugLog("ì´ë¯¸ UI ìƒíƒœê°€ ì´ˆê¸°í™”ë¨ - onend ìŠ¤í‚µ");
            return;
          }

          setIsRecording(false);
          recordingStartTime.current = null;
          setRecordingDuration(0);
          setAudioLevel(0);

          if (animationRef.current) {
            cancelAnimationFrame(animationRef.current);
          }

          if (transcript.trim()) {
            addDebugLog(`ë©”ì‹œì§€ ì „ì†¡: "${transcript.trim()}"`);
            handleSendMessage(transcript.trim());
            setTranscript("");
          }
        };

        recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
          addDebugLog(`ìŒì„± ì¸ì‹ ì˜¤ë¥˜: ${event.error}`);
          console.error("ìŒì„± ì¸ì‹ ì˜¤ë¥˜:", event.error);

          // ì˜¤ë¥˜ ë°œìƒì‹œ ê°•ì œë¡œ ìƒíƒœ ì´ˆê¸°í™”
          setIsRecording(false);
          setRecognitionState("idle");
          recordingStartTime.current = null;
          setRecordingDuration(0);
          setAudioLevel(0);

          if (animationRef.current) {
            cancelAnimationFrame(animationRef.current);
          }

          // íŠ¹ì • ì˜¤ë¥˜ì˜ ê²½ìš° ì¬ì‹œì‘ ì‹œë„
          if (event.error === "aborted" || event.error === "audio-capture") {
            addDebugLog("ì˜¤ë¥˜ë¡œ ì¸í•œ ì¬ì‹œì‘ ì‹œë„");
            setTimeout(() => {
              if (transcript.trim()) {
                handleSendMessage(transcript.trim());
                setTranscript("");
              }
            }, 200);
          }
        };
      }
    } else {
      addDebugLog("ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €");
    }

    return () => {
      // ì»´í¬ë„ŒíŠ¸ ì–¸ë§ˆìš´íŠ¸ ì‹œ ì •ë¦¬
      if (streamRef.current) {
        streamRef.current.getTracks().forEach((track) => track.stop());
      }
      if (audioContextRef.current) {
        audioContextRef.current.close();
      }
      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }
    };
  }, [transcript]);

  const handleSendMessage = async (message: string) => {
    if (!message.trim()) return;

    // ë‚´ ëŒ€ì‚¬ ì¶”ê°€
    const newMessages = [...messages, { speaker: myName, text: message }];
    setMessages(newMessages);
    setIsLoading(true);

    try {
      // ë°±ì—”ë“œ API í˜¸ì¶œ
      const res = await fetch("http://localhost:3001/api/chat", {
        method: "POST",
        headers: { "Content-Type": "application/json" },
        body: JSON.stringify({
          characterId,
          userInput: message,
        }),
      });
      const data = await res.json();

      // ìºë¦­í„° ì‘ë‹µ ì¶”ê°€
      setMessages([
        ...newMessages,
        { speaker: characterName, text: data.reply },
      ]);
    } catch (err) {
      console.error("Error:", err);
      addDebugLog(`API í˜¸ì¶œ ì˜¤ë¥˜: ${err}`);
      // ì—ëŸ¬ ì‹œ ë”ë¯¸ ì‘ë‹µ
      setMessages([
        ...newMessages,
        {
          speaker: characterName,
          text: "ì£„ì†¡í•´ìš”, ì ì‹œ ë¬¸ì œê°€ ìˆì–´ìš”. ë‹¤ì‹œ ë§ì”€í•´ ì£¼ì„¸ìš”!",
        },
      ]);
    } finally {
      setIsLoading(false);
    }
  };

  const toggleRecording = () => {
    if (!recognitionRef.current) {
      addDebugLog("ìŒì„± ì¸ì‹ ê¸°ëŠ¥ ì—†ìŒ");
      alert("ìŒì„± ì¸ì‹ì´ ì§€ì›ë˜ì§€ ì•ŠëŠ” ë¸Œë¼ìš°ì €ì…ë‹ˆë‹¤.");
      return;
    }

    addDebugLog(
      `í˜„ì¬ ìƒíƒœ: recognitionState=${recognitionState}, isRecording=${isRecording}`
    );

    if (
      isRecording ||
      recognitionState === "running" ||
      recognitionState === "starting"
    ) {
      // ë…¹ìŒ ì¤‘ë‹¨
      if (recognitionState === "stopping") {
        addDebugLog("ì´ë¯¸ ì¤‘ë‹¨ ì²˜ë¦¬ ì¤‘ - ë¬´ì‹œ");
        return;
      }

      addDebugLog("ë…¹ìŒ ì¤‘ë‹¨ ìš”ì²­");
      setRecognitionState("stopping");

      // ì¦‰ì‹œ UI ìƒíƒœ ë³€ê²½
      setIsRecording(false);
      recordingStartTime.current = null;
      setRecordingDuration(0);
      setAudioLevel(0);

      if (animationRef.current) {
        cancelAnimationFrame(animationRef.current);
      }

      // ìŒì„± ì¸ì‹ ì¤‘ë‹¨
      try {
        recognitionRef.current.stop();
        addDebugLog("ìŒì„± ì¸ì‹ stop() í˜¸ì¶œ ì™„ë£Œ");
      } catch (error) {
        addDebugLog(`stop() ì˜¤ë¥˜: ${error}`);
        setRecognitionState("idle"); // ì˜¤ë¥˜ ì‹œ ê°•ì œë¡œ idle ìƒíƒœë¡œ
      }

      // ê°•ì œë¡œ í…ìŠ¤íŠ¸ ì²˜ë¦¬
      setTimeout(() => {
        if (transcript.trim()) {
          addDebugLog(`ê°•ì œ ë©”ì‹œì§€ ì „ì†¡: "${transcript.trim()}"`);
          handleSendMessage(transcript.trim());
          setTranscript("");
        }
        setRecognitionState("idle"); // ì¼ì • ì‹œê°„ í›„ idleë¡œ ê°•ì œ ë³€ê²½
      }, 500);
    } else if (recognitionState === "idle") {
      // ë…¹ìŒ ì‹œì‘
      addDebugLog("ë…¹ìŒ ì‹œì‘ ìš”ì²­");
      setRecognitionState("starting");
      setTranscript("");

      try {
        recognitionRef.current.start();
        addDebugLog("ìŒì„± ì¸ì‹ start() í˜¸ì¶œ ì™„ë£Œ");
      } catch (error) {
        addDebugLog(`start() ì˜¤ë¥˜: ${error}`);
        setRecognitionState("idle");

        // InvalidStateErrorì¸ ê²½ìš° ê°•ì œë¡œ ì¤‘ë‹¨ í›„ ì¬ì‹œì‘
        if (error instanceof Error && error.name === "InvalidStateError") {
          addDebugLog("InvalidStateError - ê°•ì œ ì¤‘ë‹¨ í›„ ì¬ì‹œì‘ ì‹œë„");
          try {
            recognitionRef.current?.stop();
            setTimeout(() => {
              if (recognitionState === "idle" && recognitionRef.current) {
                recognitionRef.current.start();
                addDebugLog("ì¬ì‹œì‘ ì‹œë„ ì™„ë£Œ");
              }
            }, 300);
          } catch (retryError) {
            addDebugLog(`ì¬ì‹œì‘ ì‹¤íŒ¨: ${retryError}`);
          }
        }
      }
    } else {
      addDebugLog(`ì˜ëª»ëœ ìƒíƒœì—ì„œ í† ê¸€ ì‹œë„: ${recognitionState}`);
    }
  };

  return (
    <div className="flex flex-col min-h-screen bg-gray-100 relative">
      {/* ë””ë²„ê·¸ íŒ¨ë„ í† ê¸€ ë²„íŠ¼ */}
      <button
        onClick={() => setShowDebugPanel(!showDebugPanel)}
        className="fixed top-4 right-4 z-30 bg-blue-500 text-white px-3 py-1 rounded text-sm"
      >
        {showDebugPanel ? "ë””ë²„ê·¸ ìˆ¨ê¸°ê¸°" : "ë””ë²„ê·¸ ë³´ê¸°"}
      </button>

      {/* ë””ë²„ê·¸ íŒ¨ë„ */}
      {showDebugPanel && (
        <div className="fixed top-16 right-4 w-80 bg-white border rounded-lg shadow-lg z-30 p-4 max-h-96 overflow-y-auto">
          <h3 className="font-bold mb-2">ğŸ¤ ìŒì„± ë…¹ìŒ ìƒíƒœ</h3>

          {/* í˜„ì¬ ìƒíƒœ */}
          <div className="mb-3 p-2 bg-gray-50 rounded">
            <p className="text-sm">
              <span className="font-medium">ìƒíƒœ:</span>
              <span className={isRecording ? "text-red-600" : "text-green-600"}>
                {isRecording ? " ğŸ”´ ë…¹ìŒ ì¤‘" : " â­• ëŒ€ê¸° ì¤‘"}
              </span>
            </p>
            <p className="text-sm">
              <span className="font-medium">Recognition ìƒíƒœ:</span>
              <span
                className={`ml-1 ${
                  recognitionState === "running"
                    ? "text-red-600"
                    : recognitionState === "starting"
                    ? "text-yellow-600"
                    : recognitionState === "stopping"
                    ? "text-orange-600"
                    : "text-green-600"
                }`}
              >
                {recognitionState === "idle"
                  ? "ğŸŸ¢ ëŒ€ê¸°"
                  : recognitionState === "starting"
                  ? "ğŸŸ¡ ì‹œì‘ ì¤‘"
                  : recognitionState === "running"
                  ? "ğŸ”´ ì‹¤í–‰ ì¤‘"
                  : "ğŸŸ  ì¢…ë£Œ ì¤‘"}
              </span>
            </p>
            {isRecording && (
              <>
                <p className="text-sm">
                  <span className="font-medium">ì‹œê°„:</span> {recordingDuration}
                  ì´ˆ
                </p>
                <p className="text-sm">
                  <span className="font-medium">ìŒëŸ‰:</span>
                  <span className="ml-1">
                    {audioLevel > 50 ? "ğŸ”Š" : audioLevel > 20 ? "ğŸ”‰" : "ğŸ”ˆ"}{" "}
                    {audioLevel}/255
                  </span>
                </p>
                <div className="w-full bg-gray-200 rounded-full h-2 mt-1">
                  <div
                    className="bg-green-500 h-2 rounded-full transition-all duration-100"
                    style={{
                      width: `${Math.min(100, (audioLevel / 255) * 100)}%`,
                    }}
                  ></div>
                </div>
              </>
            )}
          </div>

          {/* í˜„ì¬ ì¸ì‹ëœ í…ìŠ¤íŠ¸ */}
          {transcript && (
            <div className="mb-3 p-2 bg-yellow-50 border border-yellow-200 rounded">
              <p className="text-xs text-gray-600 mb-1">ì¸ì‹ëœ í…ìŠ¤íŠ¸:</p>
              <p className="text-sm">{transcript}</p>
            </div>
          )}

          {/* ë””ë²„ê·¸ ë¡œê·¸ */}
          <div>
            <p className="text-xs font-medium mb-1">ë””ë²„ê·¸ ë¡œê·¸:</p>
            <div className="text-xs bg-black text-green-400 p-2 rounded font-mono h-32 overflow-y-auto">
              {debugLogs.map((log, idx) => (
                <div key={idx}>{log}</div>
              ))}
            </div>
          </div>
        </div>
      )}

      {/* ê¸°ì¡´ UI ì½”ë“œ */}
      <div className="absolute inset-0 z-0">
        <img
          src={backgroundImage}
          alt="ë°°ê²½"
          className="w-full h-full object-cover"
        />
      </div>
      <div className="flex-1 flex items-center justify-center bg-white/30 relative z-10">
        <img
          src={characterImage}
          alt={characterName}
          className="max-h-[70vh] object-contain"
        />
      </div>

      {/* ëŒ€í™”ì°½ */}
      <div className="bg-white/60 absolute bottom-0 left-0 right-0 w-full backdrop-blur-sm border-t z-20">
        {/* ëŒ€í™” ê¸°ë¡ */}
        <div className="h-40 overflow-y-auto rounded-lg p-5 text-left">
          {messages.map((msg, idx) => (
            <p
              key={idx}
              className={`mb-2 ${
                msg.speaker === myName ? "text-blue-600" : "text-purple-600"
              }`}
            >
              <span className="font-bold">{msg.speaker}: </span>
              {msg.text}
            </p>
          ))}
          {isLoading && <p className="text-gray-500">ìƒëŒ€ê°€ ì…ë ¥ ì¤‘...</p>}
        </div>

        {/* ìŒì„± ì…ë ¥ ì˜ì—­ */}
        <div className="flex flex-col items-center space-y-3 mb-10">
          {/* ìŒì„± ì¸ì‹ ìƒíƒœ í‘œì‹œ */}
          {transcript && (
            <div className="w-full bg-yellow-50 border border-yellow-200 rounded-lg p-3">
              <p className="text-sm text-gray-600 mb-1">ì¸ì‹ëœ ìŒì„±:</p>
              <p className="text-gray-800">{transcript}</p>
            </div>
          )}

          {/* ì‹¤ì‹œê°„ ì˜¤ë””ì˜¤ ë ˆë²¨ í‘œì‹œ */}
          {isRecording && (
            <div className="flex items-center space-x-2">
              <Volume2 size={16} />
              <div className="w-32 bg-gray-200 rounded-full h-2">
                <div
                  className="bg-red-500 h-2 rounded-full transition-all duration-100"
                  style={{
                    width: `${Math.min(100, (audioLevel / 255) * 100)}%`,
                  }}
                ></div>
              </div>
              <span className="text-xs text-gray-600">
                {recordingDuration}s
              </span>
            </div>
          )}

          {/* ìŒì„± ì…ë ¥ ë²„íŠ¼ */}
          <button
            onClick={toggleRecording}
            disabled={isLoading}
            className={`
              w-16 h-16 rounded-full flex items-center justify-center text-white font-bold text-lg
              transition-all duration-200 transform hover:scale-105 active:scale-95
              ${
                isRecording
                  ? "bg-red-500 hover:bg-red-600 animate-pulse"
                  : "bg-[#ceccff] hover:bg-[#b6b4f0]"
              }
              ${isLoading ? "opacity-50 cursor-not-allowed" : ""}
            `}
          >
            {isRecording ? <MicOff size={24} /> : <Mic size={24} />}
          </button>

          <p className="text-sm text-gray-600 text-center">
            {isRecording ? (
              <span className="text-red-600 font-medium">
                ğŸ¤ ë…¹ìŒ ì¤‘... ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ ì™„ë£Œ
              </span>
            ) : (
              "ë§ˆì´í¬ ë²„íŠ¼ì„ ëˆŒëŸ¬ ìŒì„±ìœ¼ë¡œ ëŒ€í™”í•˜ì„¸ìš”"
            )}
          </p>
        </div>
      </div>
    </div>
  );
}
